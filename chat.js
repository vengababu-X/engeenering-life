// --- Common Elements and Variables (used across pages) ---
const API_KEY = "AIzaSyD6t67ErOa0NY7ZoAhREjzIhuuoK2IZzV0"; // Replace with your actual API key
const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${API_KEY}`;

const userData = {
    message: null,
    file: {
        data: null,
        mime_type: null,
    },
    language: localStorage.getItem("chatbotLanguage") || "en", // Default or saved language
};

let ttsEnabled = false;
let currentSpeechUtterance = null; // To control play/pause

// Helper function to create message elements in the chat
const createMessageElement = (content, ...classes) => {
    const div = document.createElement("div");
    div.classList.add("message", ...classes);
    div.innerHTML = content;
    return div;
};

// Function to convert text to speech
const speak = (text) => {
    if (currentSpeechUtterance && window.speechSynthesis.speaking) {
        window.speechSynthesis.cancel(); // Stop any ongoing speech
    }

    if (ttsEnabled && 'speechSynthesis' in window) {
        const sentences = text.split(/[.!?\n]/g).filter(s => s.trim() !== "");
        const maxChunkLength = 1500; // Increased chunk length for better flow

        const chunks = [];
        let currentChunk = "";

        for (const sentence of sentences) {
            if ((currentChunk + sentence).length <= maxChunkLength) {
                currentChunk += sentence + ". ";
            } else {
                chunks.push(currentChunk.trim());
                currentChunk = sentence + ". ";
            }
        }
        if (currentChunk.trim() !== "") {
            chunks.push(currentChunk.trim());
        }

        const speakChunk = (index) => {
            if (index >= chunks.length) {
                currentSpeechUtterance = null;
                // Update Play/Pause button on Image Analyzer if applicable
                const playPauseButton = document.getElementById('play-pause-description-button');
                if (playPauseButton && playPauseButton.textContent === 'â¸ï¸ Pause') {
                    playPauseButton.textContent = 'â¯ï¸ Play/Pause';
                }
                return; // Stop if all chunks are processed
            }

            currentSpeechUtterance = new SpeechSynthesisUtterance(chunks[index]);
            currentSpeechUtterance.lang = userData.language; // Set TTS language
            currentSpeechUtterance.rate = 1;
            currentSpeechUtterance.pitch = 1;

            currentSpeechUtterance.onend = () => {
                speakChunk(index + 1); // Speak the next chunk when the current one ends
            };

            currentSpeechUtterance.onerror = (event) => {
                console.error('SpeechSynthesisUtterance.onerror', event);
            };

            window.speechSynthesis.speak(currentSpeechUtterance);
        };

        speakChunk(0); // Start speaking the first chunk
    } else {
        console.error("Text-to-speech not supported or disabled in this browser.");
    }
};

const pauseSpeech = () => {
    if (window.speechSynthesis.speaking) {
        window.speechSynthesis.pause();
    }
};

const resumeSpeech = () => {
    if (window.speechSynthesis.paused) {
        window.speechSynthesis.resume();
    }
};

const stopSpeech = () => {
    if (window.speechSynthesis.speaking) {
        window.speechSynthesis.cancel();
    }
    currentSpeechUtterance = null;
    const playPauseButton = document.getElementById('play-pause-description-button');
    if (playPauseButton && playPauseButton.textContent === 'â¸ï¸ Pause') {
        playPauseButton.textContent = 'â¯ï¸ Play/Pause';
    }
};

// Function to translate text using Google Translate API (Placeholder, needs a server-side proxy for real use)
const translateText = async (text, targetLanguage) => {
    // For a real application, you'd use a server-side proxy for Google Translate API
    // Direct client-side calls are generally not recommended due to API key exposure and CORS.
    // This is a simplified client-side representation.
    const translateUrl = `https://translation.googleapis.com/language/translate/v2?key=${API_KEY}`;
    const requestBody = {
        q: text,
        target: targetLanguage,
    };

    try {
        const response = await fetch(translateUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(requestBody),
        });
        const data = await response.json();
        if (!response.ok) throw new Error(data.error.message);
        return data.data.translations[0].translatedText; // Return translated text
    } catch (error) {
        console.error("Translation error:", error);
        return text; // Return original text if translation fails
    }
};

// Predefined responses
const predefinedResponses = {
    hi: {
        en: "Hi there! How can I help you?",
        es: "Â¡Hola! Â¿CÃ³mo puedo ayudarte?",
        fr: "Salut! Comment puis-je vous aider?",
        de: "Hallo! Wie kann ich Ihnen helfen?",
        hi: "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤?",
        ja: "ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã¾ã™ã‹ï¼Ÿ",
        zh: "ä½ å¥½ï¼æˆ‘èƒ½å¸®ä½ ä»€ä¹ˆï¼Ÿ",
        ta: "à®µà®£à®•à¯à®•à®®à¯! à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®Žà®ªà¯à®ªà®Ÿà®¿ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯?",
    },
    hello: {
        en: "Hello! What can I do for you today?",
        es: "Hola! Â¿QuÃ© puedo hacer por ti hoy?",
        fr: "Bonjour! Que puis-je faire pour vous aujourd'hui?",
        de: "Hallo! Was kann ich heute fÃ¼r Sie tun?",
        hi: "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤†à¤œ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤•à¥à¤¯à¤¾ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤?",
        ja: "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã¾ã™ã‹ï¼Ÿ",
        zh: "ä½ å¥½ï¼ä»Šå¤©æˆ‘èƒ½ä¸ºä½ åšä»€ä¹ˆï¼Ÿ",
        ta: "à®µà®£à®•à¯à®•à®®à¯! à®‡à®©à¯à®±à¯ à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®Žà®©à¯à®© à®šà¯†à®¯à¯à®¯ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯?",
    },
    whoAreYou: {
        en: "I am Smart Vision AI, an AI assistant created by Team XKINGS. RAMU THE KING I can help with image analysis and chat.",
        es: "Soy Smart Vision AI, un asistente de IA creado por Team XKINGS. Miembros del equipo: . Puedo ayudar con el anÃ¡lisis de imÃ¡genes y el chat.",
        fr: "Je suis Smart Vision AI, un assistant IA crÃ©Ã© par Team XKINGS. Je peux vous aider avec l'analyse d'images et le chat.",
        de: "Ich bin Smart Vision AI, ein KI-Assistent, der von Team Mac erstellt wurde. Teammitglieder: Maheedhar, Thoufiq, Lahari, Revathi, Sukanya. Ich kann bei der Bildanalyse und im Chat helfen.",
        hi: "à¤®à¥ˆà¤‚ à¤¸à¥à¤®à¤¾à¤°à¥à¤Ÿ à¤µà¤¿à¤œà¤¨ à¤à¤†à¤ˆ à¤¹à¥‚à¤, à¤Ÿà¥€à¤® à¤®à¥ˆà¤• à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤¬à¤¨à¤¾à¤¯à¤¾ à¤—à¤¯à¤¾ à¤à¤• à¤à¤†à¤ˆ à¤¸à¤¹à¤¾à¤¯à¤•à¥¤ à¤Ÿà¥€à¤® à¤•à¥‡ à¤¸à¤¦à¤¸à¥à¤¯: à¤®à¤¹à¥‡à¤¶à¥à¤µà¤°, à¤¤à¥Œà¤«à¥€à¤•, à¤²à¤¾à¤¹à¤¿à¤°à¥€, à¤°à¥‡à¤µà¤¤à¥€, à¤¸à¥à¤•à¤¨à¥à¤¯à¤¾à¥¤ à¤®à¥ˆà¤‚ à¤›à¤µà¤¿ à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤”à¤° à¤šà¥ˆà¤Ÿ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤à¥¤",
        ja: "ç§ã¯ãƒãƒ¼ãƒ Macã«ã‚ˆã£ã¦ä½œæˆã•ã‚ŒãŸAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€Smart Vision AIã§ã™ã€‚ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ï¼šãƒžãƒ’ãƒ€ãƒ«ã€ãƒˆã‚¥ãƒ•ã‚£ã‚¯ã€ãƒ©ãƒãƒªã€ãƒ¬ãƒ´ã‚¡ãƒ†ã‚£ã€ã‚¹ã‚«ãƒ³ãƒ¤ã€‚ç”»åƒåˆ†æžã¨ãƒãƒ£ãƒƒãƒˆã‚’æ”¯æ´ã§ãã¾ã™ã€‚",
        zh: "æˆ‘æ˜¯Smart Vision AIï¼Œä¸€ä¸ªç”±Team Macåˆ›å»ºçš„AIåŠ©æ‰‹ã€‚å›¢é˜Ÿæˆå‘˜ï¼šMaheedharã€Thoufiqã€Lahariã€Revathiã€Sukanyaã€‚æˆ‘å¯ä»¥å¸®åŠ©è¿›è¡Œå›¾åƒåˆ†æžå’ŒèŠå¤©ã€‚",
        ta: "à®¨à®¾à®©à¯ à®¸à¯à®®à®¾à®°à¯à®Ÿà¯ à®µà®¿à®·à®©à¯ à®à®, à®Ÿà¯€à®®à¯ à®®à¯‡à®•à¯ à®•à¯à®´à¯à®µà®¾à®²à¯ à®‰à®°à¯à®µà®¾à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿ à®’à®°à¯ AI à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯. . à®¨à®¾à®©à¯ à®ªà®Ÿ à®ªà®•à¯à®ªà¯à®ªà®¾à®¯à¯à®µà¯ à®®à®±à¯à®±à¯à®®à¯ à®…à®°à®Ÿà¯à®Ÿà¯ˆà®¯à®¿à®²à¯ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯.",
    },
    mahi: {
        en: "Maheedhar is one of the talented individuals who created me.",
        es: "Maheedhar es una de las personas talentosas que me crearon.",
        fr: "Maheedhar est l'un des individus talentueux qui m'ont crÃ©Ã©.",
        de: "Maheedhar ist einer der talentierten Individuen, die mich erschaffen haben.",
        hi: "à¤®à¤¹à¥‡à¤¶à¥à¤µà¤° à¤‰à¤¨ à¤ªà¥à¤°à¤¤à¤¿à¤­à¤¾à¤¶à¤¾à¤²à¥€ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¥‡ à¤à¤• à¤¹à¥ˆà¤‚ à¤œà¤¿à¤¨à¥à¤¹à¥‹à¤‚à¤¨à¥‡ à¤®à¥à¤à¥‡ à¤¬à¤¨à¤¾à¤¯à¤¾ à¤¹à¥ˆà¥¤",
        ja: "ãƒžãƒ’ãƒ€ãƒ«ã¯ç§ã‚’ä½œæˆã—ãŸæ‰èƒ½ã‚ã‚‹äººç‰©ã®ä¸€äººã§ã™ã€‚",
        zh: "Maheedharæ˜¯åˆ›é€ æˆ‘çš„æ‰åŽæ¨ªæº¢çš„ä¸ªäººä¹‹ä¸€ã€‚",
        ta: "à®®à®¹à®¿à®¤à®°à¯ à®Žà®©à¯à®©à¯ˆ à®‰à®°à¯à®µà®¾à®•à¯à®•à®¿à®¯ à®¤à®¿à®±à®®à¯ˆà®¯à®¾à®© à®¨à®ªà®°à¯à®•à®³à®¿à®²à¯ à®’à®°à¯à®µà®°à¯.",
    },
    playVideo: {
        en: "Opening YouTube for you!",
        es: "Abriendo YouTube para ti!",
        fr: "Ouverture de YouTube pour vous!",
        de: "Ã–ffne YouTube fÃ¼r dich!",
        hi: "à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤¯à¥‚à¤Ÿà¥à¤¯à¥‚à¤¬ à¤–à¥‹à¤² à¤°à¤¹à¤¾ à¤¹à¥‚à¤!",
        ja: "YouTubeã‚’é–‹ã„ã¦ã„ã¾ã™ï¼",
        zh: "æ­£åœ¨ä¸ºä½ æ‰“å¼€YouTubeï¼",
        ta: "à®‰à®™à¯à®•à®³à¯à®•à¯à®•à®¾à®• YouTube à®¤à®¿à®±à®•à¯à®•à®¿à®±à®¤à¯!",
    },
    openGoogle: {
        en: "Navigating to Google now!",
        es: "Navegando a Google ahora!",
        fr: "AccÃ¨s Ã  Google maintenant!",
        de: "Gehe jetzt zu Google!",
        hi: "à¤…à¤¬ à¤—à¥‚à¤—à¤² à¤ªà¤° à¤œà¤¾ à¤°à¤¹à¤¾ à¤¹à¥‚à¤!",
        ja: "ä»Šã™ãGoogleã«ç§»å‹•ã—ã¾ã™ï¼",
        zh: "æ­£åœ¨å¯¼èˆªåˆ°Googleï¼",
        ta: "à®‡à®ªà¯à®ªà¯‹à®¤à¯ Google-à®•à¯à®•à¯ à®šà¯†à®²à¯à®•à®¿à®±à®¤à¯!",
    },
    openMaps: {
        en: "Opening Google Maps for you!",
        es: "Abriendo Google Maps para ti!",
        fr: "Ouverture de Google Maps pour vous!",
        de: "Ã–ffne Google Maps fÃ¼r dich!",
        hi: "à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤—à¥‚à¤—à¤² à¤®à¥ˆà¤ªà¥à¤¸ à¤–à¥‹à¤² à¤°à¤¹à¤¾ à¤¹à¥‚à¤!",
        ja: "Googleãƒžãƒƒãƒ—ã‚’é–‹ã„ã¦ã„ã¾ã™ï¼",
        zh: "æ­£åœ¨ä¸ºä½ æ‰“å¼€Googleåœ°å›¾ï¼",
        ta: "à®‰à®™à¯à®•à®³à¯à®•à¯à®•à®¾à®• Google Maps à®¤à®¿à®±à®•à¯à®•à®¿à®±à®¤à¯!",
    },
    arise: {
        en: "Opening face detection interface.",
        es: "Abriendo la interfaz de detecciÃ³n de rostros.",
        fr: "Ouverture de l'interface de dÃ©tection de visage.",
        de: "GesichtserkennungsoberflÃ¤che wird geÃ¶ffnet.",
        hi: "à¤šà¥‡à¤¹à¤°à¤¾ à¤ªà¤¹à¤šà¤¾à¤¨ à¤‡à¤‚à¤Ÿà¤°à¤«à¤¼à¥‡à¤¸ à¤–à¥‹à¤² à¤°à¤¹à¤¾ à¤¹à¥ˆà¥¤",
        ja: "é¡”æ¤œå‡ºã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’é–‹ã„ã¦ã„ã¾ã™ã€‚",
        zh: "æ­£åœ¨æ‰“å¼€äººè„¸è¯†åˆ«ç•Œé¢ã€‚",
        ta: "à®®à¯à®• à®…à®™à¯à®•à¯€à®•à®¾à®° à®‡à®Ÿà¯ˆà®®à¯à®•à®®à¯ à®¤à®¿à®±à®•à¯à®•à®¿à®±à®¤à¯.",
    }
};

// Function to navigate to index1.html (for "arise" command and camera)
const navigateToFaceDetection = () => {
    // For a real-world app, "index1.html" would be your actual face detection page.
    // Make sure index1.html exists and implements the face detection logic.
    window.open("index1.html", "_blank");
};


// --- Logic Specific to Image Analyzer (`image.html`) ---
if (document.getElementById('image-input')) {
    const imageInput = document.getElementById('image-input');
    const imageUploadArea = document.getElementById('image-upload-area');
    const uploadedImagePreview = document.getElementById('uploaded-image-preview');
    const imagePreviewContainer = document.getElementById('image-preview-container');
    const clearImageButton = document.getElementById('clear-image-button');
    const analyzeImageButton = document.getElementById('analyze-image-button');
    const aiDescriptionText = document.getElementById('ai-description-text');
    const speakDescriptionButton = document.getElementById('speak-description-button');
    const playPauseDescriptionButton = document.getElementById('play-pause-description-button');

    // Load TTS preference for Image Analyzer too
    ttsEnabled = localStorage.getItem("ttsEnabled") === "true";
    if (speakDescriptionButton) {
        speakDescriptionButton.textContent = ttsEnabled ? "ðŸ”Š Speak (On)" : "ðŸ”Š Speak (Off)";
    }

    // Drag and Drop functionality
    imageUploadArea.addEventListener('click', () => imageInput.click());
    imageUploadArea.addEventListener('dragover', (e) => {
        e.preventDefault();
        imageUploadArea.style.borderColor = '#007bff';
        imageUploadArea.style.backgroundColor = '#e6f7ff';
    });
    imageUploadArea.addEventListener('dragleave', () => {
        imageUploadArea.style.borderColor = '#ccc';
        imageUploadArea.style.backgroundColor = '#f9f9f9';
    });
    imageUploadArea.addEventListener('drop', (e) => {
        e.preventDefault();
        imageUploadArea.style.borderColor = '#ccc';
        imageUploadArea.style.backgroundColor = '#f9f9f9';
        const files = e.dataTransfer.files;
        if (files.length > 0) {
            handleImageFile(files[0]);
        }
    });

    imageInput.addEventListener('change', (e) => {
        if (e.target.files.length > 0) {
            handleImageFile(e.target.files[0]);
        }
    });

    clearImageButton.addEventListener('click', () => {
        userData.file = { data: null, mime_type: null };
        uploadedImagePreview.src = '#';
        uploadedImagePreview.classList.add('hidden');
        imagePreviewContainer.classList.add('hidden');
        clearImageButton.classList.add('hidden');
        analyzeImageButton.classList.add('disabled');
        analyzeImageButton.disabled = true;
        aiDescriptionText.textContent = '';
        speakDescriptionButton.classList.add('hidden');
        playPauseDescriptionButton.classList.add('hidden');
        stopSpeech(); // Stop any speech
    });

    analyzeImageButton.addEventListener('click', async () => {
        if (userData.file.data) {
            aiDescriptionText.textContent = 'Analyzing image...';
            speakDescriptionButton.classList.add('hidden');
            playPauseDescriptionButton.classList.add('hidden');
            stopSpeech(); // Stop any previous speech

            const requestBody = {
                contents: [
                    {
                        parts: [
                            { text: "Describe this image in detail. Mention objects, colors, textures, and arrangement." },
                            { inline_data: { data: userData.file.data, mime_type: userData.file.mime_type } },
                        ],
                    },
                ],
            };

            const requestOptions = {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify(requestBody),
            };

            try {
                const response = await fetch(API_URL, requestOptions);
                const data = await response.json();
                if (!response.ok) throw new Error(data.error.message || "Unknown API error");

                const apiResponseText = data.candidates[0].content.parts[0].text
                    .replace(/\*\*(.*?)\*\*/g, "$1") // Remove bold markdown
                    .trim();

                const translatedResponse = await translateText(apiResponseText, userData.language);
                aiDescriptionText.textContent = translatedResponse;
                speakDescriptionButton.classList.remove('hidden');
                playPauseDescriptionButton.classList.remove('hidden');

                if (ttsEnabled) {
                    speak(translatedResponse);
                }

            } catch (error) {
                console.error("Image analysis error:", error);
                aiDescriptionText.textContent = `Error: ${error.message}`;
                aiDescriptionText.style.color = "#ff0000";
            }
        }
    });

    speakDescriptionButton.addEventListener('click', () => {
        const textToSpeak = aiDescriptionText.textContent;
        if (textToSpeak && textToSpeak !== 'Analyzing image...' && textToSpeak.startsWith('Error') === false) {
            ttsEnabled = !ttsEnabled;
            localStorage.setItem("ttsEnabled", ttsEnabled); // Save TTS preference
            speakDescriptionButton.textContent = ttsEnabled ? "ðŸ”Š Speak (On)" : "ðŸ”Š Speak (Off)";

            if (ttsEnabled) {
                speak(textToSpeak);
                playPauseDescriptionButton.textContent = 'â¸ï¸ Pause';
            } else {
                stopSpeech();
                playPauseDescriptionButton.textContent = 'â¯ï¸ Play/Pause';
            }
        }
    });

    playPauseDescriptionButton.addEventListener('click', () => {
        if (window.speechSynthesis.speaking && !window.speechSynthesis.paused) {
            pauseSpeech();
            playPauseDescriptionButton.textContent = 'â–¶ï¸ Play';
        } else if (window.speechSynthesis.paused) {
            resumeSpeech();
            playPauseDescriptionButton.textContent = 'â¸ï¸ Pause';
        } else {
            // If nothing is speaking, start speaking
            const textToSpeak = aiDescriptionText.textContent;
            if (textToSpeak && textToSpeak !== 'Analyzing image...' && textToSpeak.startsWith('Error') === false) {
                speak(textToSpeak);
                playPauseDescriptionButton.textContent = 'â¸ï¸ Pause';
                ttsEnabled = true; // Enable TTS if started from play
                localStorage.setItem("ttsEnabled", true);
                speakDescriptionButton.textContent = "ðŸ”Š Speak (On)";
            }
        }
    });

    function handleImageFile(file) {
        if (!file.type.startsWith('image/')) {
            alert('Please upload an image file (e.g., JPEG, PNG, GIF).');
            return;
        }

        const reader = new FileReader();
        reader.onload = (e) => {
            const base64String = e.target.result.split(',')[1];
            userData.file = {
                data: base64String,
                mime_type: file.type,
            };
            uploadedImagePreview.src = e.target.result;
            uploadedImagePreview.classList.remove('hidden');
            imagePreviewContainer.classList.remove('hidden');
            clearImageButton.classList.remove('hidden');
            analyzeImageButton.classList.remove('disabled');
            analyzeImageButton.disabled = false;
            aiDescriptionText.textContent = ''; // Clear previous description
            speakDescriptionButton.classList.add('hidden');
            playPauseDescriptionButton.classList.add('hidden');
            stopSpeech();
        };
        reader.readAsDataURL(file);
    }
}


// --- Logic Specific to Live Chat (`voice.html`) ---
if (document.getElementById('chat-body')) {
    const chatBody = document.querySelector(".chat-body");
    const messageInput = document.querySelector(".message-input");
    const sendMessageButton = document.querySelector("#send-message");
    const fileInput = document.querySelector("#file-input");
    const voiceInputButton = document.querySelector("#voice-input");
    const clearFileButton = document.querySelector("#clear-file");
    const toggleTTSButton = document.querySelector("#toggle-tts");
    const languageSelector = document.querySelector("#language-selector");
    const saveChatButton = document.querySelector("#save-chat");
    const clearChatButton = document.querySelector("#clear-chat");
    const resetChatButton = document.querySelector("#reset-chat");

    // Initialize Speech Recognition
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = userData.language; // Set initial language

    // Load saved language preference
    const savedLanguage = localStorage.getItem("chatbotLanguage");
    if (savedLanguage) {
        userData.language = savedLanguage;
        languageSelector.value = savedLanguage;
        recognition.lang = savedLanguage; // Set speech recognition language
    }

    // Load TTS preference
    ttsEnabled = localStorage.getItem("ttsEnabled") === "true";
    toggleTTSButton.textContent = ttsEnabled ? "Disable TTS" : "Enable TTS";
    if (ttsEnabled) {
        toggleTTSButton.classList.add('active');
    } else {
        toggleTTSButton.classList.remove('active');
        stopSpeech(); // Stop speech if TTS is disabled
    }

    // Function to generate the bot response using the Gemini API
    const generateBotResponse = async (incomingMessageDiv) => {
        const messageElement = incomingMessageDiv.querySelector(".message-text");

        const userMessage = userData.message.toLowerCase().trim();

        // Check for predefined responses first
        let responseFound = false;
        let botResponseText = '';

        if (userMessage === "hi") {
            botResponseText = predefinedResponses.hi[userData.language] || predefinedResponses.hi.en;
            responseFound = true;
        } else if (userMessage === "hello") {
            botResponseText = predefinedResponses.hello[userData.language] || predefinedResponses.hello.en;
            responseFound = true;
        } else if (userMessage === "mahi") {
            botResponseText = predefinedResponses.mahi[userData.language] || predefinedResponses.mahi.en;
            responseFound = true;
        } else if (userMessage === "play video" || userMessage === "open youtube") {
            botResponseText = predefinedResponses.playVideo[userData.language] || predefinedResponses.playVideo.en;
            window.open("https://www.youtube.com", "_blank"); // Open YouTube in a new tab
            responseFound = true;
        } else if (userMessage === "open maps") {
            botResponseText = predefinedResponses.openMaps[userData.language] || predefinedResponses.openMaps.en;
            window.open("https://maps.google.com", "_blank"); // Open Google Maps in a new tab
            responseFound = true;
        } else if (userMessage === "open google") {
            botResponseText = predefinedResponses.openGoogle[userData.language] || predefinedResponses.openGoogle.en;
            window.open("https://www.google.co.in/", "_blank"); // Open Google in a new tab
            responseFound = true;
        } else if (userMessage === "who are you?" || userMessage === "who r u?" || userMessage === "who r u" ||
                   userMessage === "who are u" || userMessage === "who are u?" || userMessage === "who are you" ||
                   userMessage === "what are you" || userMessage === "who invented u" || userMessage === "who invented you") {
            botResponseText = predefinedResponses.whoAreYou[userData.language] || predefinedResponses.whoAreYou.en;
            responseFound = true;
        } else if (userMessage === "arise") {
            botResponseText = predefinedResponses.arise[userData.language] || predefinedResponses.arise.en;
            navigateToFaceDetection(); // Navigate to index1.html
            responseFound = true;
        }

        if (responseFound) {
            messageElement.innerText = botResponseText;
            incomingMessageDiv.classList.remove("thinking");
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
            sendMessageButton.disabled = false;
            speak(botResponseText);
            return; // Stop further processing
        }

        // If no predefined response, proceed with API call
        const translatedUserMessage = await translateText(userData.message, "en"); // Translate to English for API

        // Prepare the body for the API request
        const requestBody = {
            contents: [
                {
                    parts: [
                        { text: translatedUserMessage || "Describe this image." },
                        ...userData.file.data
                            ? [{ inline_data: { data: userData.file.data, mime_type: userData.file.mime_type } }]
                            : [],
                    ],
                },
            ],
        };

        const requestOptions = {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(requestBody),
        };

        try {
            const response = await fetch(API_URL, requestOptions);
            const data = await response.json();
            if (!response.ok) throw new Error(data.error.message || "Unknown API error");

            const apiResponseText = data.candidates[0].content.parts[0].text
                .replace(/\*\*(.*?)\*\*/g, "$1") // Remove markdown bolding
                .trim();

            // Translate bot response to user's language
            const translatedResponse = await translateText(apiResponseText, userData.language);
            messageElement.innerText = translatedResponse;

            // Add speak button next to each bot message
            const speakButton = document.createElement('button');
            speakButton.classList.add('speak-message-button');
            speakButton.innerHTML = 'ðŸ”Š';
            speakButton.title = 'Speak this message';
            speakButton.onclick = () => speak(translatedResponse);
            incomingMessageDiv.appendChild(speakButton);

            speak(translatedResponse); // Speak the bot's response
        } catch (error) {
            console.error(error);
            messageElement.innerText = `Error: ${error.message}`;
            messageElement.style.color = "#ff0000";
        } finally {
            incomingMessageDiv.classList.remove("thinking");
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
            sendMessageButton.disabled = false;
        }
    };

    // Handle outgoing user messages
    const handleOutgoingMessage = (e) => {
        e.preventDefault();
        userData.message = messageInput.value.trim();
        messageInput.value = "";
        sendMessageButton.disabled = true;

        // Check if the message is "arise"
        if (userData.message.toLowerCase() === "arise") {
            navigateToFaceDetection(); // Navigate to index1.html
            // Create a message for "arise" command
            const messageContent = `<div class="message-text">${userData.message}</div>`;
            const outgoingMessageDiv = createMessageElement(messageContent, "user-message");
            chatBody.appendChild(outgoingMessageDiv);
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });

            setTimeout(() => {
                const botResponseText = predefinedResponses.arise[userData.language] || predefinedResponses.arise.en;
                const messageContentBot = `
                    <div class="bot-avatar"></div>
                    <div class="message-text">${botResponseText}</div>`;
                const incomingMessageDiv = createMessageElement(messageContentBot, "bot-message");
                chatBody.appendChild(incomingMessageDiv);
                chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });

                const speakButton = document.createElement('button');
                speakButton.classList.add('speak-message-button');
                speakButton.innerHTML = 'ðŸ”Š';
                speakButton.title = 'Speak this message';
                speakButton.onclick = () => speak(botResponseText);
                incomingMessageDiv.appendChild(speakButton);

                speak(botResponseText);
                sendMessageButton.disabled = false;
            }, 600);
            return; // Stop further processing
        }


        // Create and display user message
        const messageContent = `<div class="message-text">${userData.message || "Uploaded file"}</div>
            ${userData.file.data ? `<img src="data:${userData.file.mime_type};base64,${userData.file.data}" class="attachment" />` : ""
        }`;
        const outgoingMessageDiv = createMessageElement(messageContent, "user-message");
        chatBody.appendChild(outgoingMessageDiv);
        chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });

        // Simulate bot response with thinking indicator after a delay
        setTimeout(() => {
            const messageContent = `
                <div class="bot-avatar"></div>
                <div class="message-text">
                    <div class="thinking-indicator">
                        <div class="dot"></div>
                        <div class="dot"></div>
                        <div class="dot"></div>
                    </div>
                </div>`;
            const incomingMessageDiv = createMessageElement(messageContent, "bot-message", "thinking");
            chatBody.appendChild(incomingMessageDiv);
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
            generateBotResponse(incomingMessageDiv);
        }, 600);

        // Clear file data after sending
        userData.file = { data: null, mime_type: null };
        if (clearFileButton) { // Ensure button exists before trying to access
            clearFileButton.style.display = "none";
        }
        document.querySelector(".file-preview, .file-name")?.remove(); // Remove preview
    };

    // Handle Enter key press for sending messages
    messageInput.addEventListener("keydown", (e) => {
        const userMessage = e.target.value.trim();
        if (e.key === "Enter" && userMessage) {
            e.preventDefault(); // Prevent default form submission behavior
            handleOutgoingMessage(e); // Trigger the function
        }
    });

    // Handle Send button click
    sendMessageButton.addEventListener("click", (e) => {
        const userMessage = messageInput.value.trim();
        if (userMessage || userData.file.data) { // Allow sending with just a file
            handleOutgoingMessage(e); // Trigger the function
        }
    });

    // Handle file input change
    fileInput.addEventListener("change", () => {
        const file = fileInput.files[0];
        if (!file) return;

        // Add file type validation
        if (!file.type.startsWith('image/') && !file.type.startsWith('video/') && !file.type.startsWith('audio/') && !file.type.startsWith('text/')) {
            alert('Please upload an image, video, audio, or text file.');
            return;
        }

        const reader = new FileReader();
        reader.onload = (e) => {
            const base64String = e.target.result.split(",")[1];
            // Store file data in userData
            userData.file = {
                data: base64String,
                mime_type: file.type,
            };
            // Display file name or preview
            // Remove any existing preview/filename before adding new one
            document.querySelector(".file-preview, .file-name")?.remove();

            if (file.type.startsWith("image/")) {
                const preview = `<img src="${e.target.result}" alt="Uploaded Image" class="attachment file-preview" />`;
                messageInput.insertAdjacentHTML("beforebegin", preview);
            } else {
                const fileName = `<div class="file-name">${file.name}</div>`;
                messageInput.insertAdjacentHTML("beforebegin", fileName);
            }
            fileInput.value = ""; // Clear the input
            clearFileButton.style.display = "inline-block"; // Show the clear button

            // Enable send button if a file is attached
            sendMessageButton.disabled = false;
        };
        reader.readAsDataURL(file);
    });

    // Handle clear file button click
    clearFileButton.addEventListener("click", () => {
        userData.file = { data: null, mime_type: null }; // Clear file data
        fileInput.value = ""; // Clear the input
        clearFileButton.style.display = "none"; // Hide the clear button
        document.querySelector(".file-preview, .file-name")?.remove(); // Remove preview
        sendMessageButton.disabled = messageInput.value.trim() === ""; // Disable if no text
    });

    // Handle file upload button click
    document.querySelector("#file-upload").addEventListener("click", () => fileInput.click());

    // Handle voice input button click
    voiceInputButton.addEventListener("click", () => {
        if (voiceInputButton.classList.contains("recording")) {
            recognition.stop(); // Stop recording if already active
            voiceInputButton.classList.remove("recording");
        } else {
            recognition.start(); // Start recording
            voiceInputButton.classList.add("recording");
            messageInput.value = "Listening..."; // Provide immediate feedback
            sendMessageButton.disabled = true;
        }
    });

    // Handle speech recognition result
    recognition.addEventListener("result", async (e) => {
        const transcript = e.results[0][0].transcript.trim().toLowerCase();
        messageInput.value = transcript;
        voiceInputButton.classList.remove("recording");
        userData.message = transcript;

        // Handle special commands from voice input
        let responseHandled = false;

        if (transcript === "arise") {
            navigateToFaceDetection(); // Navigate to index1.html
            const response = predefinedResponses.arise[userData.language] || predefinedResponses.arise.en;
            const outgoingMessageDiv = createMessageElement(`<div class="message-text">${transcript}</div>`, "user-message");
            chatBody.appendChild(outgoingMessageDiv);
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
            setTimeout(() => {
                const incomingMessageDiv = createMessageElement(`<div class="message-text">${response}</div>`, "bot-message");
                chatBody.appendChild(incomingMessageDiv);
                chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
                const speakButton = document.createElement('button');
                speakButton.classList.add('speak-message-button');
                speakButton.innerHTML = 'ðŸ”Š';
                speakButton.title = 'Speak this message';
                speakButton.onclick = () => speak(response);
                incomingMessageDiv.appendChild(speakButton);
                speak(response);
                sendMessageButton.disabled = false;
            }, 600);
            responseHandled = true;
        } else if (transcript === "play video" || transcript === "open youtube") {
            const response = predefinedResponses.playVideo[userData.language] || predefinedResponses.playVideo.en;
            const outgoingMessageDiv = createMessageElement(`<div class="message-text">${transcript}</div>`, "user-message");
            chatBody.appendChild(outgoingMessageDiv);
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
            setTimeout(() => {
                const incomingMessageDiv = createMessageElement(`<div class="message-text">${response}</div>`, "bot-message");
                chatBody.appendChild(incomingMessageDiv);
                chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
                const speakButton = document.createElement('button');
                speakButton.classList.add('speak-message-button');
                speakButton.innerHTML = 'ðŸ”Š';
                speakButton.title = 'Speak this message';
                speakButton.onclick = () => speak(response);
                incomingMessageDiv.appendChild(speakButton);
                speak(response);
                sendMessageButton.disabled = false;
            }, 600);
            window.open("https://www.youtube.com", "_blank"); // Open YouTube in a new tab
            responseHandled = true;
        } else if (transcript === "open maps") {
            const response = predefinedResponses.openMaps[userData.language] || predefinedResponses.openMaps.en;
            const outgoingMessageDiv = createMessageElement(`<div class="message-text">${transcript}</div>`, "user-message");
            chatBody.appendChild(outgoingMessageDiv);
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
            setTimeout(() => {
                const incomingMessageDiv = createMessageElement(`<div class="message-text">${response}</div>`, "bot-message");
                chatBody.appendChild(incomingMessageDiv);
                chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
                const speakButton = document.createElement('button');
                speakButton.classList.add('speak-message-button');
                speakButton.innerHTML = 'ðŸ”Š';
                speakButton.title = 'Speak this message';
                speakButton.onclick = () => speak(response);
                incomingMessageDiv.appendChild(speakButton);
                speak(response);
                sendMessageButton.disabled = false;
            }, 600);
            window.open("https://maps.google.com", "_blank"); // Open Google Maps in a new tab
            responseHandled = true;
        } else if (transcript === "open google") {
            const response = predefinedResponses.openGoogle[userData.language] || predefinedResponses.openGoogle.en;
            const outgoingMessageDiv = createMessageElement(`<div class="message-text">${transcript}</div>`, "user-message");
            chatBody.appendChild(outgoingMessageDiv);
            chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
            setTimeout(() => {
                const incomingMessageDiv = createMessageElement(`<div class="message-text">${response}</div>`, "bot-message");
                chatBody.appendChild(incomingMessageDiv);
                chatBody.scrollTo({ top: chatBody.scrollHeight, behavior: "smooth" });
                const speakButton = document.createElement('button');
                speakButton.classList.add('speak-message-button');
                speakButton.innerHTML = 'ðŸ”Š';
                speakButton.title = 'Speak this message';
                speakButton.onclick = () => speak(response);
                incomingMessageDiv.appendChild(speakButton);
                speak(response);
                sendMessageButton.disabled = false;
            }, 600);
            window.open("https://www.google.co.in/", "_blank"); // Open Google in a new tab
            responseHandled = true;
        }

        if (!responseHandled) {
            handleOutgoingMessage(new Event("auto-send")); // Trigger normal message handling
        }
    });

    // Handle speech recognition end
    recognition.addEventListener("end", () => {
        voiceInputButton.classList.remove("recording");
        sendMessageButton.disabled = false; // Re-enable send button
    });

    // Handle speech recognition error
    recognition.addEventListener("error", (e) => {
        console.error("Speech recognition error:", e.error);
        voiceInputButton.classList.remove("recording");
        alert("Speech recognition failed. Please ensure your microphone is enabled and try again.");
        sendMessageButton.disabled = false; // Re-enable send button
        messageInput.value = ""; // Clear input on error
    });

    // Toggle TTS
    toggleTTSButton.addEventListener("click", () => {
        ttsEnabled = !ttsEnabled;
        toggleTTSButton.textContent = ttsEnabled ? "Disable TTS" : "Enable TTS";
        if (ttsEnabled) {
            toggleTTSButton.classList.add('active');
        } else {
            toggleTTSButton.classList.remove('active');
            stopSpeech(); // Stop speech if TTS is disabled
        }
        localStorage.setItem("ttsEnabled", ttsEnabled); // Save TTS preference
    });

    // Handle language selection
    languageSelector.addEventListener("change", (e) => {
        userData.language = e.target.value;
        recognition.lang = userData.language; // Update speech recognition language
        localStorage.setItem("chatbotLanguage", userData.language); // Save language preference
    });

    // Handle camera button click
    document.getElementById("camera-button").addEventListener("click", () => {
        navigateToFaceDetection(); // Navigate to index1.html
    });

    // Chat options functionality
    saveChatButton.addEventListener('click', () => {
        const messages = [];
        chatBody.querySelectorAll('.message').forEach(msgDiv => {
            const type = msgDiv.classList.contains('user-message') ? 'user' : 'bot';
            const text = msgDiv.querySelector('.message-text')?.textContent.trim() || '';
            const imageSrc = msgDiv.querySelector('.attachment')?.src || null;
            messages.push({ type, text, imageSrc });
        });
        const chatData = JSON.stringify(messages, null, 2);
        const blob = new Blob([chatData], { type: 'application/json' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'chatbot_chat_history.json';
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        alert('Chat saved!');
    });

    clearChatButton.addEventListener('click', () => {
        if (confirm("Are you sure you want to clear the entire chat? This action cannot be undone.")) {
            chatBody.innerHTML = '';
            stopSpeech(); // Stop any ongoing speech
            alert('Chat cleared!');
        }
    });

    resetChatButton.addEventListener('click', () => {
        if (confirm("Are you sure you want to reset the chat? This will clear all messages and reset settings.")) {
            chatBody.innerHTML = '';
            userData.file = { data: null, mime_type: null };
            userData.message = null;
            messageInput.value = '';
            clearFileButton.style.display = 'none';
            document.querySelector(".file-preview, .file-name")?.remove();
            stopSpeech();
            alert('Chat reset!');
        }
    });

    // Restore chat history from localStorage on page load (Optional, but good for UX)
    // You would need to add logic to save chat messages to localStorage when they are added.
    // For simplicity, this example doesn't include saving history to localStorage.
  }
